# Guide: Proposal Review and Revision

## Introduction

Writing is rewriting. The difference between a good proposal and a great proposal often comes down to revision. This guide provides systematic approaches for evaluating, revising, and polishing your research proposal to submission quality.

---

## Part 1: The Revision Mindset

### Distance Creates Clarity

After intense writing, you're too close to see your proposal clearly. Create distance:
- Wait 24+ hours before major revisions
- Read in a different format (print vs. screen)
- Read in a different location
- Have others read and respond

### Be Your Own Skeptic

When revising, adopt the mindset of a skeptical reviewer:
- "Why should I believe this?"
- "Is this really feasible?"
- "What could go wrong?"
- "Why is this better than alternatives?"

If you can't answer these questions, neither can reviewers.

### The Goal of Revision

Revision is not about:
- Making it longer
- Adding more fancy words
- Defending your current text

Revision is about:
- Making ideas clearer
- Strengthening arguments
- Removing obstacles to understanding
- Making the proposal impossible to ignore

---

## Part 2: Structured Self-Review

### The Three-Pass Method

**Pass 1: Big Picture (30 minutes)**
- Read the entire proposal in one sitting
- Note overall impressions
- Identify major gaps or problems
- Assess logical flow

**Pass 2: Section-by-Section (2 hours)**
- Evaluate each section against rubric
- Rate sections on 1-5 scale
- Write notes on strengths and weaknesses
- Identify specific fixes needed

**Pass 3: Line-by-Line (3+ hours)**
- Read every sentence critically
- Check for clarity and precision
- Verify claims are supported
- Polish language

### Section-Specific Review

**Project Summary Review:**
- [ ] Does overview capture the essence of the project?
- [ ] Is intellectual merit clearly articulated?
- [ ] Are broader impacts specific and compelling?
- [ ] Can it stand alone without the full proposal?
- [ ] Is it exactly one page?

**Specific Aims Review:**
- [ ] Does the hook establish importance immediately?
- [ ] Is the gap clearly identified?
- [ ] Is the hypothesis/approach clearly stated?
- [ ] Are aims specific and measurable?
- [ ] Is the impact statement compelling?

**Background Review:**
- [ ] Is the field context appropriate?
- [ ] Is prior work fairly represented?
- [ ] Is the gap well-defined?
- [ ] Is innovation clearly articulated?
- [ ] Is significance established?

**Research Plan Review:**
- [ ] Is methodology detailed and specific?
- [ ] Are methods justified?
- [ ] Are pitfalls and alternatives addressed?
- [ ] Is the timeline realistic?
- [ ] Are success criteria measurable?

**Broader Impacts Review:**
- [ ] Are training plans specific?
- [ ] Is broadening participation addressed concretely?
- [ ] Are educational components integrated?
- [ ] Is dissemination well-planned?
- [ ] Is societal impact clear?

---

## Part 3: Using Agency Rubrics

### NSF Merit Review

NSF evaluates proposals on two criteria with equal weight:

**Intellectual Merit:**

| Rating | Description |
|--------|-------------|
| Excellent | Innovative, well-designed, clearly advances knowledge |
| Very Good | Strong approach, good innovation, advances knowledge |
| Good | Sound approach, some innovation, worthwhile contribution |
| Fair | Acceptable approach, limited innovation or contribution |
| Poor | Weak approach, little innovation, unclear contribution |

**Questions reviewers answer:**
1. Potential to advance knowledge?
2. Creative, original, transformative concepts?
3. Well-reasoned, well-organized plan?
4. Qualified team?
5. Adequate resources?

**Broader Impacts:**

| Rating | Description |
|--------|-------------|
| Excellent | Significant, well-planned societal benefit |
| Very Good | Clear benefit, good planning |
| Good | Some benefit, adequate planning |
| Fair | Limited benefit or planning |
| Poor | No clear benefit |

**Questions reviewers answer:**
1. Potential to benefit society?
2. Creative, original, transformative concepts?
3. Well-reasoned, well-organized plan?
4. Qualified team?
5. Adequate resources?

### DOE Merit Review

**Technical/Scientific Merit (50%):**
- Quality and innovation of approach
- Awareness of prior work
- Appropriateness of methods
- Feasibility of execution

**Relevance (30%):**
- Alignment with DOE mission
- Potential for scientific impact
- Appropriateness of proposed work
- Qualifications of team

**Budget Appropriateness (20%):**
- Reasonable cost-benefit
- Justified expenses
- Appropriate timeline

### Self-Rating Exercise

Rate your proposal sections honestly:

| Section | IM (1-5) | BI (1-5) | Notes |
|---------|----------|----------|-------|
| Summary | ___ | ___ | ______________ |
| Aims | ___ | ___ | ______________ |
| Background | ___ | ___ | ______________ |
| Aim 1 | ___ | ___ | ______________ |
| Aim 2 | ___ | ___ | ______________ |
| Aim 3 | ___ | ___ | ______________ |
| Timeline | ___ | ___ | ______________ |
| Broader Impacts | ___ | ___ | ______________ |

**Sections rated 3 or below need significant revision.**

---

## Part 4: Common Weaknesses and Fixes

### Weakness: Vague Methodology

**Symptom:** Reviewers ask "How exactly will they do this?"

**Diagnosis:**
- Methods not specific enough
- Parameters not stated
- Success criteria unclear

**Fix:**
- Add specific protocols
- State numerical parameters
- Define measurable outcomes

**Before:**
> We will develop new codes using optimization methods.

**After:**
> We will optimize codes using a genetic algorithm with population size 500, mutation rate 0.02, and fitness function weighted for bias ratio Î·, running for 2000 generations or until fitness plateaus for 100 generations.

---

### Weakness: Unsupported Claims

**Symptom:** Reviewers ask "Why should I believe this?"

**Diagnosis:**
- Claims without evidence
- Missing citations
- Overconfident assertions

**Fix:**
- Add citations
- Include preliminary data
- Soften claims or provide support

**Before:**
> Our approach will solve the decoherence problem.

**After:**
> Preliminary simulations suggest our approach reduces logical error rates by 3x for bias ratios of 10:1 (Figure 1), consistent with theoretical predictions [ref]. We will validate this advantage on hardware in Aim 3.

---

### Weakness: Weak Broader Impacts

**Symptom:** Low broader impacts score

**Diagnosis:**
- Generic or vague statements
- Not connected to research
- No evidence of commitment

**Fix:**
- Add specific activities
- Connect to research expertise
- Provide evidence (track record, letters)

**Before:**
> We will train students and do outreach.

**After:**
> We will train 2 PhD students and 4 REU undergraduates, with REU recruitment focused on partner HBCUs (Howard University, letter attached). The PI's group includes 40% women and 30% URM, exceeding field averages. All students will present at national conferences and co-author publications.

---

### Weakness: Overly Ambitious Scope

**Symptom:** Reviewers question feasibility

**Diagnosis:**
- Too many aims
- Timeline too compressed
- Resources don't match scope

**Fix:**
- Reduce scope
- Add time or resources
- Reframe as focused contribution

**Before:**
> We will develop complete error correction for all quantum computing platforms.

**After:**
> We will develop optimized error correction codes for superconducting qubits with biased noise. While our methods are general, we focus on this platform to enable thorough validation on available hardware.

---

### Weakness: Missing Connections

**Symptom:** Proposal reads as disconnected pieces

**Diagnosis:**
- Aims don't build on each other
- Background doesn't motivate methods
- Impact doesn't follow from aims

**Fix:**
- Add explicit connections
- Strengthen transitions
- Show logical progression

**Before:**
> Aim 1... Aim 2... Aim 3... (independent descriptions)

**After:**
> Aim 1 establishes the theoretical framework for biased-noise codes. Building on these optimized code designs, Aim 2 develops decoders that leverage the same noise structure. Aim 3 validates both contributions on hardware, using codes from Aim 1 and decoders from Aim 2.

---

### Weakness: Passive Voice Overuse

**Symptom:** Writing feels weak and bureaucratic

**Diagnosis:**
- Too much "will be done"
- Actor unclear
- Responsibility diffused

**Fix:**
- Convert to active voice
- Identify who does what
- Make claims confidently

**Before:**
> The codes will be optimized and the results will be analyzed.

**After:**
> We will optimize codes using genetic algorithms and analyze results using statistical comparison to standard approaches.

---

## Part 5: The Revision Process

### Stage 1: Triage (Day 1)

**Goal:** Identify what needs fixing

1. Read entire proposal without editing
2. Note impressions and problems
3. Complete self-review rubric
4. Compile issue list

**Categorize issues:**
- **Critical:** Must fix or proposal fails
- **Important:** Significantly improves proposal
- **Nice-to-have:** Would be better but not essential

### Stage 2: Major Revisions (Days 2-3)

**Goal:** Fix critical and important issues

1. Address critical issues first
2. Work on one issue at a time
3. Check that fixes don't create new problems
4. Verify all critical issues resolved

**Common major revisions:**
- Strengthening methodology
- Adding missing sections
- Clarifying aims
- Improving significance

### Stage 3: Incorporate Feedback (Day 3)

**Goal:** Learn from others' perspectives

1. Review all feedback received
2. Categorize: essential vs. optional
3. Address essential items
4. Note items not addressed (and why)

**Handling conflicting feedback:**
- Trust consistent feedback from multiple readers
- Consider expertise of each reviewer
- Make your own judgment on disputed points

### Stage 4: Polish (Day 4)

**Goal:** Make every sentence count

1. Read for flow and rhythm
2. Cut unnecessary words
3. Strengthen weak verbs
4. Check transitions

**Word-level polish:**
- Replace weak verbs (is, has, does)
- Cut filler words (very, really, basically)
- Use parallel structure in lists
- Vary sentence length

### Stage 5: Technical Check (Day 5)

**Goal:** Ensure compliance and consistency

1. Verify formatting requirements
2. Check page limits
3. Complete references
4. Finalize figures

**Formatting checklist:**
- [ ] Correct font and size
- [ ] Correct margins
- [ ] Page numbers present
- [ ] Section headings consistent
- [ ] Figure/table numbering correct
- [ ] Citations formatted correctly

### Stage 6: Final Review (Day 6-7)

**Goal:** Last chance for improvements

1. Print and read on paper
2. Read aloud
3. Have someone else proofread
4. Verify all issues addressed

---

## Part 6: Editing Techniques

### The "So What?" Test

After every major statement, ask "So what?" If you can't answer, the statement needs work.

**Weak:**
> Quantum computers can solve certain problems efficiently.

*So what?*

**Strong:**
> Quantum computers can solve optimization problems in hours that would take classical computers millions of years, enabling breakthroughs in drug discovery and materials design that are currently impossible.

### The Zoom Test

Can a reviewer understand your key points by reading only:
- Title and abstract
- First sentences of each paragraph
- Figures and captions

If not, restructure to frontload key information.

### The Substitution Test

Replace your abstract with a competitor's. Does the proposal still make sense? If so, your abstract is too generic.

### The Red Pen Pass

Print your proposal and mark in red:
- Every vague word
- Every passive voice sentence
- Every unsupported claim
- Every undefined term

Then address each red mark.

---

## Part 7: Final Quality Checks

### Consistency Check

- [ ] Terminology consistent throughout
- [ ] Numbers match (e.g., aim counts)
- [ ] Timeline matches methodology
- [ ] Budget matches activities
- [ ] Figures match text descriptions

### Completeness Check

- [ ] All required sections present
- [ ] All figures cited in text
- [ ] All references complete
- [ ] All acronyms defined
- [ ] All collaborators mentioned

### Compliance Check

- [ ] Page limits met
- [ ] Font and margins correct
- [ ] Required statements included
- [ ] File format correct
- [ ] File size within limits

### Logic Check

- [ ] Claims are supported
- [ ] Arguments are sound
- [ ] Methodology matches aims
- [ ] Timeline is feasible
- [ ] Risks are addressed

---

## Part 8: Common Last-Minute Issues

### Issue: Over Page Limit

**Quick fixes:**
- Remove unnecessary words (very, really, that)
- Combine sentences
- Reduce white space
- Shrink figures slightly (maintain readability)
- Cut least essential content

**Do not:**
- Reduce font size below minimum
- Reduce margins below requirements
- Remove required sections

### Issue: Missing References

**Quick fixes:**
- Search reference manager for cited names
- Check bibliography of similar papers
- Use Google Scholar for quick lookups
- Mark [ref] and fill in before submission

### Issue: Weak Specific Aims

**Quick fixes:**
- Strengthen opening hook
- Clarify gap statement
- Make aims more specific
- Quantify targets

### Issue: Vague Methodology

**Quick fixes:**
- Add specific parameters
- Name tools and software
- Include step-by-step protocols
- Define success criteria

---

## Part 9: Post-Submission Learning

### Regardless of Outcome

After submitting (or receiving feedback):
1. Note what worked well
2. Identify recurring weaknesses
3. Collect feedback for future
4. Start file for next proposal

### If Funded

- Thank reviewers (in your head)
- Note strengths to replicate
- Begin planning execution
- Document what worked

### If Not Funded

- Request detailed reviews
- Analyze constructive feedback
- Distinguish valid from invalid criticism
- Plan revision for resubmission
- Consider different program/agency

---

## Summary: The Revision Checklist

### Week 208 Day-by-Day

**Day 1:** Self-review with rubrics
- [ ] Complete three-pass review
- [ ] Rate all sections
- [ ] Compile issue list
- [ ] Prioritize revisions

**Day 2:** Major revisions
- [ ] Address critical issues
- [ ] Strengthen methodology
- [ ] Clarify aims
- [ ] Add missing elements

**Day 3:** Peer feedback
- [ ] Review all feedback
- [ ] Address essential items
- [ ] Verify fixes work

**Day 4:** Polish
- [ ] Active voice throughout
- [ ] Cut unnecessary words
- [ ] Strengthen language
- [ ] Check transitions

**Day 5:** Technical check
- [ ] Formatting compliance
- [ ] Page limits
- [ ] References complete
- [ ] Figures finalized

**Day 6-7:** Final review
- [ ] Complete read-through
- [ ] External proofread
- [ ] Verify all issues addressed
- [ ] Prepare submission

---

*"The proposal you submit is the best you could do in the time available. The proposal that gets funded is the best in the competition. Close the gap through relentless revision."*
